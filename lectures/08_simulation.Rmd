---
title: "Simulation"
output: html_notebook
---

Simulation useful to empirically (observed/experienced) calculate something

`p-value` for a single t-test.

```{r}
n <- 25
delta <- 0.5
delta.sd <- 2
x <- rnorm(n, delta, delta.sd)
t.test(x, alternative='two.sided', mu=0)$p.value
```

Calculate power by resampling and testing each `p-value`.

```{r}
mean(replicate(1e3, {
    x <- rnorm(n, delta, delta.sd)
    t.test(x, alternative='two.sided', mu=0)$p.value
}) < 0.05)
```

# Exercise

In the above, the sample size is 25.  Increasing the sample size will increase the power.

What sample size will give power 90%?

```{r}
```

There's a function to do this:

```{r}
power.t.test(n, delta, delta.sd, 0.05, type='one.sample')$power
power.t.test(delta=delta, sd=delta.sd, sig.level=0.05, type='one.sample', power=0.9)$n
```

# Bootstrapping

Why use it?

Classical inference can be non-robust, and difficult

It allows us to estimate the sampling distribution of a statistic empirically without making assumptions about the form of the population.

* population, though sampling, produces sample
* resampling the sample generates bootstrap sample

```{r}
(x <- rnorm(10))
sample(x, 10, replace=TRUE)
```

```{r}
x <- rnorm(10)
bootmean <- numeric(1000)
for(i in seq_along(bootmean)) {
    bootmean[i] <- mean(sample(x, 10, replace=TRUE))
}
hist(bootmean)
# our bootstrap estimate
mean(bootmean)
```

Through sampling we may introduce error, or bias.

* bias: mean(bootmean) - truth(0)

Two types of error

* sampling error: does the sample represent the population?
* bootstrap error: enumerating bootstrap samples

# A statement of truth

Confidence intervals are better than point estimates.

# Confidence Intervals

```{r}
data(anorexia, package='MASS')
weight <- anorexia[,'Prewt']
# assume normal distribution?
hist(weight, breaks=20)
```

```{r}
conf.int <- matrix(nrow=999, ncol=2)
bmeans <- numeric(999)
for(i in seq(nrow(conf.int))) {
  r <- sample(weight, replace=TRUE)
  conf.int[i,1] <- mean(r) + qnorm(0.025) * sd(r) / sqrt(length(r))
  conf.int[i,2] <- mean(r) + qnorm(0.975) * sd(r) / sqrt(length(r))
  bmeans[i] <- mean(r)
}
```

## parametric/normal CI

```{r}
# classical approach
mean(weight) + qnorm(c(0.025, 0.975)) * sd(weight) / sqrt(length(weight))
# obtained through simulation
mean(weight) + qnorm(c(0.025, 0.975)) * sd(bmeans)
```

## basic bootstrap

```{r}
unname(2 * mean(weight) - quantile(bmeans, c(0.975, 0.025)))
```

## bootstrap percentile

```{r}
quantile(bmeans, c(0.025, 0.975))
```

## Boot package

```{r}
library(boot)
weight_boot <- boot(weight, function(x,i) mean(x[i]), R=999)
# adds BCa, adjusted bootstrap percentile
boot.ci(weight_boot)
```

# Coverage Probability

How often does confidence interval contain true parameter value?

```{r}
true_mu <- 0
x <- rnorm(100, true_mu)
R <- 999
lower <- numeric(R)
upper <- numeric(R)
for(i in seq(R)) {
    s <- sample(x, replace=TRUE)
    xbar <- mean(s)
    s <- sd(s)
    lower[i] <- xbar + qnorm(0.025) * s / sqrt(length(x))
    upper[i] <- xbar + qnorm(0.975) * s / sqrt(length(x))
}
mean(lower < true_mu & upper > true_mu)
```

What should coverage be?
Why is it not 95%?

# Simulation overview

```{r}
true_mu <- 0
x <- rnorm(100, true_mu)
true_mu <- mean(x)
R <- 999
samples <- matrix(nrow=R, ncol=100)
res <- matrix(nrow=R, ncol=7)
res[,1] <- true_mu
for(i in seq(R)) {
  samples[i,] <- r <- sample(x, replace=TRUE)
  res[i,2] <- mu <- mean(r)
  res[i,3] <- se <- sd(r) / sqrt(length(r))
  res[i,4] <- mu + qnorm(0.025) * se
  res[i,5] <- mu + qnorm(0.975) * se
}
# coverage
res[,6] <- res[,4] < true_mu & res[,5] > true_mu
# bias
res[,7] <- res[,2] - res[,1]
```

```{r}
# empirical SE of Xbar
(emp.se <- sd(res[,2]))
# mean SE, mean sample standard error of Xbar
(mean.se <- mean(res[,3]))
(bias.se <- mean.se - emp.se)
# coverage probability
mean(res[,6])
```

# Bias-corrected, for percentile interval

```{r}
coverage <- numeric(1000)
true.mu <- 35
for(ix in seq_along(coverage)) {
  x <- rgamma(20, shape = 7, scale = 5)
  res <- replicate(999, mean(sample(x, replace=TRUE)))
  z <- qnorm(sum(res < mean(x)) / 1000)
  jkmean <- numeric(length(x))
  for(i in seq_along(x)) {
    jkmean[i] <- mean(x[-i])
  }
  num <- sum((jkmean - mean(jkmean))^3)
  den <- 6 * sum((jkmean - mean(jkmean))^2)^(3/2)
  a <- num / den
  ps <- pnorm(z + (z + qnorm(c(0.025, 0.975))) / (1 - a * (z + qnorm(c(0.025, 0.975)))))
  qs <- quantile(res, ps)
  coverage[ix] <- qs[1] < true.mu & qs[2] > true.mu
}
mean(coverage)
```

# Exercise

Suppose you have a sample of N=100 from the Gamma distribution with shape=2 and scale=1.  Calculate the 75th percentile with a basic bootstrapped 95% confidence interval for the upper quartile (75th percentile).

```{r}
```

Did the CI work?

```{r}
(truth <- quantile(rgamma(1e6, 2, 1), 0.75))
```
